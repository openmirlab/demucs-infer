{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demucs - Audio Source Separation\n",
    "\n",
    "This notebook demonstrates how to use Demucs for separating music into stems (drums, bass, other, vocals).\n",
    "\n",
    "**Features:**\n",
    "- Separate music into 4 stems (drums, bass, other, vocals)\n",
    "- Optional 6-stem separation (adds guitar and piano)\n",
    "- High-quality hybrid transformer architecture\n",
    "- Multiple pre-trained models available"
   ],
   "metadata": {
    "id": "cell-0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Installation"
   ],
   "metadata": {
    "id": "cell-1"
   }
  },
  {
   "cell_type": "code",
   "source": "# Install demucs-infer package and dependencies\n!pip install -q demucs-infer soundfile",
   "metadata": {
    "id": "cell-2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ],
   "metadata": {
    "id": "cell-3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Download Model\n",
    "\n",
    "We'll use the **htdemucs_ft** model (fine-tuned Hybrid Transformer Demucs), which provides the best quality for music separation."
   ],
   "metadata": {
    "id": "cell-4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create directories\n",
    "!mkdir -p input_songs\n",
    "!mkdir -p outputs"
   ],
   "metadata": {
    "id": "cell-5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download and cache the model (models are automatically downloaded on first use)\n",
    "from demucs_infer.pretrained import get_model\n",
    "\n",
    "model_name = \"htdemucs_ft\"  # Best quality model\n",
    "print(f\"Downloading model: {model_name}\")\n",
    "print(\"(This may take a few minutes on first run)\\n\")\n",
    "\n",
    "model = get_model(model_name)\n",
    "\n",
    "print(f\"\\nModel loaded successfully!\")\n",
    "print(f\"Sources: {model.sources}\")\n",
    "print(f\"Sample rate: {model.samplerate} Hz\")"
   ],
   "metadata": {
    "id": "cell-6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Upload Your Audio File\n",
    "\n",
    "Upload a `.wav` file to separate into stems."
   ],
   "metadata": {
    "id": "cell-7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Option 1: Upload from your computer\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to input folder\n",
    "for filename in uploaded.keys():\n",
    "    !mv \"{filename}\" input_songs/\n",
    "    print(f\"Moved {filename} to input_songs/\")"
   ],
   "metadata": {
    "id": "cell-8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Option 2: Use a sample audio (uncomment to use)\n",
    "# !wget -q -O input_songs/sample.wav \"YOUR_AUDIO_URL_HERE\""
   ],
   "metadata": {
    "id": "cell-9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check input files\n",
    "!ls -lh input_songs/"
   ],
   "metadata": {
    "id": "cell-10"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Run Source Separation\n",
    "\n",
    "Select your preferred method and run the separation:"
   ],
   "metadata": {
    "id": "cell-11"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Select Inference Method { display-mode: \"form\" }\n",
    "#@markdown Choose which method to use for audio separation:\n",
    "\n",
    "inference_method = \"CLI (Command Line)\" #@param [\"CLI (Command Line)\", \"Python API\"]\n",
    "\n",
    "print(f\"Selected method: {inference_method}\")"
   ],
   "metadata": {
    "id": "cell-12"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Run Source Separation { display-mode: \"form\" }\n",
    "#@markdown Click the play button to run separation with your selected method.\n",
    "\n",
    "if inference_method == \"CLI (Command Line)\":\n",
    "    # ============================================\n",
    "    # Option A: CLI (Command Line)\n",
    "    # ============================================\n",
    "    print(\"Running with CLI...\\n\")\n",
    "    !demucs-infer \\\n",
    "        -n htdemucs_ft \\\n",
    "        -o ./outputs \\\n",
    "        ./input_songs/*.wav\n",
    "\n",
    "else:\n",
    "    # ============================================\n",
    "    # Option B: Python API\n",
    "    # ============================================\n",
    "    print(\"Running with Python API...\\n\")\n",
    "\n",
    "    import torch\n",
    "    import soundfile as sf\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    from demucs_infer.pretrained import get_model\n",
    "    from demucs_infer.apply import apply_model\n",
    "    from demucs_infer.audio import convert_audio\n",
    "\n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model = get_model(\"htdemucs_ft\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded on {device}\\n\")\n",
    "\n",
    "    # Process files\n",
    "    input_folder = Path(\"input_songs\")\n",
    "    output_folder = Path(\"outputs\")\n",
    "\n",
    "    for audio_path in input_folder.glob(\"*.wav\"):\n",
    "        print(f\"Processing: {audio_path.name}\")\n",
    "\n",
    "        # Load audio using soundfile\n",
    "        audio, sr = sf.read(str(audio_path))\n",
    "\n",
    "        # Convert to tensor (soundfile returns [time, channels], we need [channels, time])\n",
    "        if len(audio.shape) == 1:\n",
    "            # Mono: convert to stereo\n",
    "            audio = torch.tensor(audio, dtype=torch.float32).unsqueeze(0)\n",
    "            audio = audio.expand(2, -1)\n",
    "        else:\n",
    "            # Stereo or multi-channel\n",
    "            audio = torch.tensor(audio.T, dtype=torch.float32)\n",
    "\n",
    "        # Convert to model's sample rate if needed\n",
    "        if sr != model.samplerate:\n",
    "            audio = convert_audio(audio, sr, model.samplerate, model.audio_channels)\n",
    "            sr = model.samplerate\n",
    "\n",
    "        # Add batch dimension and move to device\n",
    "        wav = audio.unsqueeze(0).to(device)\n",
    "\n",
    "        # Run separation\n",
    "        with torch.no_grad():\n",
    "            sources = apply_model(model, wav, device=device)\n",
    "\n",
    "        # Save each stem using soundfile\n",
    "        stem_name = audio_path.stem\n",
    "        stem_output_dir = output_folder / \"htdemucs_ft\" / stem_name\n",
    "        stem_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i, source_name in enumerate(model.sources):\n",
    "            source = sources[0, i].cpu().numpy().T  # [channels, time] -> [time, channels]\n",
    "            output_path = stem_output_dir / f\"{source_name}.wav\"\n",
    "            sf.write(str(output_path), source, sr, subtype=\"FLOAT\")\n",
    "            print(f\"  Saved: {output_path}\")\n",
    "\n",
    "    print(\"\\nDone!\")"
   ],
   "metadata": {
    "id": "cell-13"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Check Output Files"
   ],
   "metadata": {
    "id": "cell-14"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Check output files\n",
    "!find outputs -name \"*.wav\" -type f"
   ],
   "metadata": {
    "id": "cell-15"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Listen to Results"
   ],
   "metadata": {
    "id": "cell-16"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Find and display all output files\n",
    "for audio_file in sorted(output_dir.rglob(\"*.wav\")):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"File: {audio_file.relative_to(output_dir)}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    display(ipd.Audio(str(audio_file)))"
   ],
   "metadata": {
    "id": "cell-17"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Download Results"
   ],
   "metadata": {
    "id": "cell-18"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download all output files as a zip\n",
    "!zip -r outputs.zip outputs/\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"outputs.zip\")"
   ],
   "metadata": {
    "id": "cell-19"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Available Models\n",
    "\n",
    "| Model | Sources | Description | Best For |\n",
    "|-------|---------|-------------|----------|\n",
    "| htdemucs_ft | 4 | Fine-tuned Hybrid Transformer | Best quality (recommended) |\n",
    "| htdemucs | 4 | Hybrid Transformer Demucs | High quality |\n",
    "| htdemucs_6s | 6 | 6-source separation | Guitar/piano extraction |\n",
    "| mdx | 4 | MDX architecture | Fast processing |\n",
    "| mdx_extra | 4 | Enhanced MDX | Better quality than mdx |\n",
    "| mdx_q | 4 | Quantized MDX | Fastest processing |\n",
    "| mdx_extra_q | 4 | Quantized enhanced MDX | Fast with good quality |\n",
    "\n",
    "See the [GitHub repository](https://github.com/openmirlab/demucs-infer) for more options."
   ],
   "metadata": {
    "id": "cell-20"
   }
  }
 ]
}